# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates
# SPDX-License-Identifier: MIT

from dataclasses import dataclass, field
from typing import Any, Literal

from typing_extensions import TypedDict


class ErrorMarker(TypedDict):
    """A simple error marker used for everywhere we need to mark an error."""

    message: str


@dataclass
class ToolCall:
    """Represents a concrete tool call."""

    tool_name: str
    """The name of the tool to call."""

    arguments: str | dict[str, Any]
    """The arguments to pass to the tool. With two possible forms:
    
    - A dictionary, which is the key-value arguments.
    - A string, which is the JSON string of the arguments.
    """

    tool_call_id: str
    """The ID of the tool call generated by LLM response."""


class ToolCallResultDict(TypedDict):
    """Represents the result of a tool call as a dict."""

    data: str | None
    error: str | None
    system_error: str | None


@dataclass
class ToolCallResult:
    """Represents the result of a tool call."""

    tool_call_id: str
    """The ID of the tool call generated by LLM response."""

    content: str | None = None
    """The content of the tool call result. Must be convert into a string."""

    error_marker: ErrorMarker | None = None
    """When some error occurs during calling the tool, the error marker will be set."""

    system_error_marker: ErrorMarker | None = None
    """Mark the error that occurs because of the system."""

    extra: dict[str, Any] = field(default_factory=dict)

    def get_content_or_error(self) -> str:
        """Return the content or error message of the tool call result."""
        if self.content is not None:
            return self.content
        elif self.error_marker is not None:
            return self.error_marker["message"]
        else:
            raise ValueError(
                "[ToolCallResult] Must have one of content or error marker."
            )


@dataclass
class LLMOutputItem:
    """Represents an item of output from the LLM."""

    role: Literal["assistant"] = "assistant"
    """The role of the output item."""

    content: str | None = None
    """The content of the output item."""

    reasoning_content: str | None = None
    """The reasoning content of the output item."""

    signature: str | None = None
    """The signature of the step, maybe generated by the `claude-thinking` models."""

    tool_calls: list[ToolCall] = field(default_factory=list)


@dataclass
class ModelResponse:
    """Represents a non-streaming model response in the conversation."""

    outputs: list[LLMOutputItem] = field(default_factory=list)

    session_id: str | None = None
    """An ID for the session."""

    error_marker: ErrorMarker | None = None
    """When some error occurs during calling LLM, the error marker will be set."""


@dataclass
class RunResult:
    """Represents the final result of an agent turn."""

    stop_reason: Literal["finished", "reach_max_steps", "error"] = "finished"

    content: str | None = None
    """The content of the output item."""

    reasoning_content: str | None = None
    """The reasoning content of the output item."""
